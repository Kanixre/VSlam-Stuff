Links and Commands
---------------------------------------------------------------------------------------------------
https://lcas.lincoln.ac.uk/nextcloud/index.php/s/q73JHG6xWwX3Lqf

-----
roscore
rosrun ORB_SLAM3 Mono Vocabulary/ORBvoc.txt Examples_old/ZED2.yaml
rosbag play --pause kg_lc_march.bag # replace with desired bag name
rosrun image_transport republish compressed in:=/front/zed_node/rgb/image_rect_color raw out:=/camera/image_raw

------
evo_ape tum GPS_march.tum KeyFrameTrajectory_yz.txt --verbose --align --correct_scale

evo_traj tum  KeyFrameTrajectory.txt -vap --ref GPS_march.tum --correct_scale
------------
void ImageGrabber::GrabNewImage(const sensor_msgs::ImageConstPtr& msg)
{
    // Convert the ROS image message to the format used by ORB-SLAM3
    cv_bridge::CvImagePtr cv_ptr;
    try
    {
        cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
    }
    catch (cv_bridge::Exception& e)
    {
        ROS_ERROR("cv_bridge exception: %s", e.what());
        return;
    }

    // Pass the image to ORB-SLAM3's tracking system
    mSLAM.TrackMonocular(cv_ptr->image, cv_ptr->header.stamp.toSec());
}


---------------------------------------------------------------------------------------------------
#!/usr/bin/env python

import rospy
import rosbag
import cv2
from cv_bridge import CvBridge
from sensor_msgs.msg import CompressedImage, Image
from image_transport import ImageTransport
import torch  # Example for a model in PyTorch
# import your segmentation model here

def process_image(image):
    # Perform segmentation on the image
    # This is a dummy function. Replace with your model's inference code.
    # For instance, if using PyTorch:
    # segmented_image = model(image_tensor)
    # Convert back to numpy if necessary
    return segmented_image

def main():
    rospy.init_node('image_processing_node')

    # Setup
    bridge = CvBridge()
    it = ImageTransport(rospy)  # For publishing and subscribing
    pub = it.advertise("segmented_images", 1)
    orbslam3_pub = it.advertise("orbslam3_input", 1)

    # Load ROS bag
    bag = rosbag.Bag('input.bag', 'r')

    for topic, msg, t in bag.read_messages(topics=['/camera/image/compressed']):
        # Convert compressed image to OpenCV format
        np_arr = np.fromstring(msg.data, np.uint8)
        cv_image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

        # Process image through segmentation model
        segmented_image = process_image(cv_image)

        # Convert back to ROS Image message
        ros_image_msg = bridge.cv2_to_imgmsg(segmented_image, encoding="bgr8")

        # Publish the segmented image
        pub.publish(ros_image_msg)

        # Optionally: Pass the segmented image to ORB-SLAM3
        orbslam3_pub.publish(ros_image_msg)

    bag.close()

if __name__ == '__main__':
    main()


---------------------------------------------------------------------------------------------------

header:
frame_id: "front_left_camera_optical_frame"
 
height: 1080
width: 1920
 
distortion_model: "plumb_bob"
 
D: [0.0, 0.0, 0.0, 0.0, 0.0]
 
K: [1057.0008544921875,       0.0,                952.2301635742188,
     0.0,                  1057.0008544921875,      553.5770263671875,     
     0.0,                                      0.0,                                           1.0]
 
R: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]
 
P: [1057.0008544921875,       0.0,                952.2301635742188,
      0.0,                                     0.0,              1057.0008544921875,
      553.5770263671875,         0.0,                                            0.0,
      0.0,                                     1.0,                                           0.0]
 
binning_x: 0
binning_y: 0
roi:
x_offset: 0
y_offset: 0
height: 0
width: 0
do_rectify: False1920


https://arxiv.org/abs/2007.11898

